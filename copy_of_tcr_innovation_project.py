# -*- coding: utf-8 -*-
"""Copy of TCR INNOVATION PROJECT

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VY81bLv4tNlEKggWXZa3PhFfPRwC3TMD

### **HR Employee Attrition**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

df=pd.read_csv("/content/HR_Employee_Attrition-1.csv")

df.head(10)

df.describe()

df.info()

df.shape

df.size

f, ax = plt.subplots(1, 2, figsize=(20,8))
ax[0] = df['Attrition'].value_counts(). plot.pie(explode=[0,0], autopct = '%1.2f%%', ax=ax[0], shadow=True)
ax[0].set_title('Income Share ')

ax[1] = sns.countplot(x='Attrition', data=df, palette='Set1')
ax[1].set_title("Frequency Distribution of Attrition")
plt.show()

ax[1] = sns.countplot(x='Attrition', data=df, palette='Set1')
ax[1].set_title("Frequency Distribution of Attrition")
plt.show()

f, ax = plt.subplots(figsize=(10,8))
ax = sns.countplot(x='Attrition', hue= 'EducationField', data=df, palette='Set1' )
ax.set_title("Frequency Distribution of Attrition")
plt.show()

x1=df.drop(["Attrition"],axis="columns",inplace=False)
y1=df["Attrition"]

x1.drop(["EmployeeNumber","EmployeeCount","Over18"],axis=1,inplace=True)

x1.info()

df["Gender"].value_counts()

df.corr()

plt.figure(figsize=(15,15))
sns.heatmap(df.corr(),annot=True,cmap='cividis_r',fmt='.0%')

def initial_eda(dataset):
  if isinstance(dataset, pd.DataFrame):
    total_na = dataset.isna().sum().sum()
    print("Total Records", dataset.shape)
    print("Total NA Records", total_na)
    cols = dataset.columns
    dtype = dataset.dtypes
    duniq = dataset.nunique()
    na_val = dataset.isna().sum()
    print("Cols dataset", "Datatype", "unique_records", "null records")
    for i in range(len(dataset.columns)):
      print("%38s %10s %10s %10s"% (cols[i], dtype[i], duniq[i], na_val[i]))
  else:
    print('error in the code ')

initial_eda(df)

pip install category-encoders

import category_encoders as ce
encoder = ce.OrdinalEncoder(cols = ['BusinessTravel', 'Department','EducationField','Gender','JobRole', 'MaritalStatus', 'OverTime'])
x1= encoder.fit_transform(x1)

x1.head(20)

x1.info()

cols=x1.columns
from sklearn.preprocessing import RobustScaler
scaler = RobustScaler()
x1= scaler.fit_transform(x1)
x1=pd.DataFrame(x1,columns=[cols])

x1.head(20)

x_train,x_test,y_train,y_test=train_test_split(x1,y1,test_size=0.3,random_state=42)

print(x_train.shape," ",x_test.shape," ")

from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(n_estimators=100, random_state=0)
rfc.fit(x_train, y_train)
y_pred1= rfc.predict(x_test)

y_pred1

from sklearn.metrics import accuracy_score
score = accuracy_score(y_test, y_pred1)
print('randomforest classifier', np.abs(score)*100)

"""### **Random Forest Accuracy = 95.46 %**"""